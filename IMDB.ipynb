{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b008e5-ec22-4e0e-852e-e88e3a89842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Her sütundaki eksik veri sayısını bul\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3ed26f-cca6-4751-827d-8d631e793c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kurty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kurty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kurty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kurty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'sentiment'], dtype='object')\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "data=pd.read_csv('IMDB Dataset.csv.zip')\n",
    "#print(data.head())\n",
    "#data.info()\n",
    "print(data.columns)\n",
    "print(data['sentiment'].value_counts())\n",
    "# Her sütundaki eksik veri sayısını bul\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9b9a98-bd2e-43b8-9769-8286aae5b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK kütüphanesinin stop-word'lerini ve lemmatizer'ını hazırla\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. HTML etiketlerini kaldır\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # 2. Noktalama işaretlerini ve rakamları kaldır\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # 3. Metni küçük harfe çevir\n",
    "    text = text.lower()\n",
    "    # 4. Kelimeleri ayır (Tokenization)\n",
    "    words = word_tokenize(text)\n",
    "    # 5. Stop-word'leri kaldır ve kelimeleri köklerine indir (Lemmatization)\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    # 6. Temizlenmiş kelimeleri tekrar birleştir\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df564331-956f-4149-8ec7-cdda040b1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punkt_tab verisi başarıyla indirildi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\kurty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "try:\n",
    "    nltk.download('punkt_tab')\n",
    "    print(\"punkt_tab verisi başarıyla indirildi.\")\n",
    "except Exception as e:\n",
    "    print(\"İndirme başarısız oldu. Hata:\", e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab0b0731-3c37-4f61-873a-caf7a7536650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Orijinal Yorum ---\n",
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
      "\n",
      "--- Temizlenmiş Yorum ---\n",
      "one reviewer mentioned watching oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home manyaryans muslim gangsta latino christian italian irish moreso scuffle death stare dodgy dealing shady agreement never far awayi would say main appeal show due fact go show wouldnt dare forget pretty picture painted mainstream audience forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard wholl sold nickel inmate wholl kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side\n"
     ]
    }
   ],
   "source": [
    "# Veri setinden rastgele bir yorum seçelim (örneğin ilk yorum)\n",
    "orijinal_yorum = data['review'][0]\n",
    "\n",
    "# Yazdığın clean_text fonksiyonu ile yorumu temizle\n",
    "temizlenmis_yorum = clean_text(orijinal_yorum)\n",
    "\n",
    "print(\"--- Orijinal Yorum ---\")\n",
    "print(orijinal_yorum)\n",
    "\n",
    "print(\"\\n--- Temizlenmiş Yorum ---\")\n",
    "print(temizlenmis_yorum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e59b713-4de9-4f1d-8998-205b65ec9c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review sentiment  \n",
      "0  one reviewer mentioned watching oz episode you...  positive  \n",
      "1  wonderful little production filming technique ...  positive  \n",
      "2  thought wonderful way spend time hot summer we...  positive  \n",
      "3  basically there family little boy jake think t...  negative  \n",
      "4  petter matteis love time money visually stunni...  positive  \n"
     ]
    }
   ],
   "source": [
    "# 'clean_text' fonksiyonunu 'review' sütununa uygula\n",
    "data['cleaned_review'] = data['review'].apply(clean_text)\n",
    "\n",
    "# Temizlenmiş verinin ilk 5 satırını göster\n",
    "print(data[['review', 'cleaned_review', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcca3f28-6d36-43a1-99fb-33c471bcdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.8, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a86c66cc-f958-4e9a-a9ac-66e1d0216109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "953c023d-432a-4558-b5c7-354466245d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vektörleştirilmiş veri boyutu: (50000, 35925)\n",
      "Eğitim seti boyutu: (40000, 35925)\n",
      "Test seti boyutu: (10000, 35925)\n"
     ]
    }
   ],
   "source": [
    "y = data['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Vektörleştirilmiş veri boyutu:\", X.shape)\n",
    "print(f\"Eğitim seti boyutu: {X_train.shape}\")\n",
    "print(f\"Test seti boyutu: {X_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72862577-73d1-412f-b156-8043ee057ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelin doğruluk oranı: 0.89\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      4961\n",
      "           1       0.88      0.91      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lojistik Regresyon modelini oluştur\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Modeli eğitim verileriyle eğit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test verileri üzerinde tahmin yap\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Modelin doğruluk oranını ölç ve yazdır\n",
    "dogruluk = accuracy_score(y_test, y_pred)\n",
    "print(f\"Modelin doğruluk oranı: {dogruluk:.2f}\\n\")\n",
    "\n",
    "# Detaylı performans raporunu göster\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a744b-84ee-4084-b0d6-dbaaeb297268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee5baf-c26c-441e-94ad-fabfefd027e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
